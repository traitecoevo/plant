##' Build an appropriately refined schedule.
##'
##' There are control options (within the \code{Parameters} object)
##' that affect how this function runs, in particular
##' \code{schedule_nsteps} and \code{schedule_eps} control how refined
##' the schedule will end up, and \code{schedule_verbose} controls if
##' details are printed to the screen during construction.
##'
##' @title Build Cohort Schedule
##' @param p Parameters object
##' @param splines A list of interpolating spine functions describing the
##' initial size distribution for the patch (generated by \code{\link{init_spline}})
##' @param n_init the number of initial cohorts to start with (default = 10)
##' @param ctrl Control object
##' @return A Parameters object, with schedule components set.  The
##' output offspring produced is also available as an attribute
##' \code{birth_rate}.
##' @author Rich FitzJohn
##' @export

build_schedule <- function(p, env = make_environment(parameters = p),
                           ctrl = scm_base_control(),
                           splines = NULL, n_init = 100) {
  p <- validate(p)

  n_spp <- length(p$strategies)
  if (n_spp == 0L || !any(p$is_resident)) {
    stop("Can't build a schedule with no residents")
  }

  eps <- ctrl$schedule_eps
  complete = FALSE

  # generate coarse initial size distribution
  if(!is.null(splines)) {
    state = lapply(splines, partition_spline, n = n_init)
    p$initial_state = unlist(lapply(state, as.vector))
    p$n_initial_cohorts = unlist(lapply(state, ncol))
  }

  # then refine cohorts
  is_error <- FALSE
  for (i in seq_len(ctrl$schedule_nsteps)) {

    # saves prev. result on error
    res <- tryCatch(
      run_scm_error(p, env, ctrl),
      error = function(e) {
        plant_log_debug(paste("Build schedule failed at step", i,
                              "Here's the original error message:\n", e), 
                        routine="schedule")

        # double arrow assigns to parent namespace (outside loop)
        is_error <<- TRUE
        
        if(exists("res"))
          return(res)
        else 
          stop("First iteration was not able to run, we suggest testing in `run_scm` before optimising the node schedule")
      })

    if(is_error) {
      p$cohort_schedule_times = res$schedule
      p$initial_state = res$initial_state
      p$n_initial_cohorts = res$n_initial_cohorts

      break
    }

    net_reproduction_ratios <- res[["net_reproduction_ratios"]]
    split <- lapply(res$err$total, function(x) x > eps)

    # schedule is resolved when no more cohorts are required
    if (!any(unlist(split), na.rm=TRUE)) {
      complete = TRUE
      plant_log_debug("All cohorts below the integration error threshold",
                routine="schedule")
      break
    }

    # schedule from SCM includes initial cohorts
    times <- res$schedule

    # split cohorts
    for (idx in seq_len(n_spp)) {

      # by introduction time
      times[[idx]] <- split_times(times[[idx]], split[[idx]])

      # or by initial size
      if(!is.null(state)) {
        state[[idx]] <- split_state(times[[idx]], split[[idx]],
                                    state[[idx]], splines[[idx]])
      }
    }

    # set schedule for next patch
    p$cohort_schedule_times <- times

    # set initial state for next patch
    p$initial_state = unlist(lapply(state, as.vector))
    p$n_initial_cohorts = unlist(lapply(state, ncol))

    msg <- sprintf("%d: Splitting {%s} times (%s)",
                   i,
                   paste(sapply(split, sum),    collapse=","),
                   paste(sapply(split, length), collapse=","))
    plant_log_debug(msg, routine="schedule", event="split", round=i)
  }

  # record useful attributes
  if(exists("res")) {
    p$cohort_schedule_ode_times <- res$ode_times
    attr(p, "net_reproduction_ratios") <- res$net_reproduction_ratios
  }

  # This gives the wrong message if integration succeeds.
  if(complete) {
    plant_log_debug("Schedule optimisation successfully completed", 
                    routine="schedule")
  } else if(i == ctrl$schedule_nsteps) {
    plant_log_debug("Maximum number of iterations reached",
                    routine="schedule")
  } else {
    plant_log_debug("Finished before maximum number of iterations reached without reaching integration error threshold",
                    routine="schedule")
  }

  # return parameters with refined schedule and corresponding initial state
  return(list(parameters = p, n_steps = i, complete = complete))
}

##' @rdname initialise_scm
##' @param i Index to extract from \code{x}
##' @param state List object with initial cohorts for each species
##' @param size_idx Index of the strategy size characteristic
##' @export
init_spline <- function(state, size_idx = 1) {
  state_to_spline <- function(x) {
    vars = rownames(x)

    s <- x[vars[size_idx], ]

    if(length(s) < 2)
      stop("At least two cohorts needed to define a spline")

    m <- c(min(s), max(s))

    # identity for size, zero for zeros, log for everything else
    f_ <- lapply(vars,
                 function(v) {
                   y = x[v, ]
                   if(v == vars[size_idx])
                     splinefun(s, y)
                   else if(v == "log_density")
                     splinefun_log(s, y)
                   else if(length(y[y>0]) == 0)
                     splinefun(s, rep(0, length(s)))
                   else
                     splinefun_loglog(s[y>0], y[y>0])
                 })

    # set bounds
    f_ <- lapply(f_, clamp_domain, m)

    # rename to: size_variable
    spline_names <- paste(vars[size_idx], vars, sep = "_")
    names(f_) <- spline_names

    # useful attributes
    attr(f_, 'size_idx') <- size_idx
    attr(f_, 'domain') <- m

    return(f_)
  }

  splines <- lapply(state, state_to_spline)
}

##' @rdname initialise_scm
##' @param splines Output of \code{\link{init_spline}}
##' @param sizes Size of initial cohorts
##' @param n Number of initial cohorts, if sizes is missing (default = 10)
##' @export
partition_spline <- function(splines, sizes=NULL, n=10) {
  if(is.null(sizes)) {
    m <- attr(splines, 'domain')
    sizes = seq(m[1], m[2], len = n)
  }

  state <- t(sapply(splines, function(f) f(rev(sizes))))

  # regex magic to remove first word and underscore
  rownames(state) <- gsub("^[^_]+(?=_)_", "", names(splines), perl=T)

  return(state)
}

split_times <- function(times, i) {
  ## Upwind splitting scheme only, which means that we will never
  ## split the last interval [assuming OK for now].  Inefficiently
  ## interleaved with sort().  These issues can change easily enough
  ## later.  The aim is making sure that we don't introduce the same
  ## point twice; one from upstream and one from downstream.
  dt <- diff(times)
  i <- which(i)

  # can't split cohorts introduced in the same time step (inc. t0)
  i <- i[dt[i] > 0]

  sort(c(times, times[i] - dt[i-1]/2))
}

split_state <- function(times, i, state, splines) {
  # Interpolates the intial size distrbution using splines, by halving
  # the size of t0 cohorts with large integration errors. A better scheme
  # would be to split by density (rather than size) but this requires a more
  # complicated splines object (see: scm_spline).

  # can only split cohorts introduced at t0
  i <- which(i)
  i <- i[times[i] == 0]

  if(length(i) == 0)
    return(state)

  size_idx <- attr(splines, 'size_idx')
  domain <- attr(splines, 'domain')

  sizes <- state[size_idx, ]
  ds <- diff(c(sizes, domain[1])) # clamp domain
  new_sizes <- sort(c(sizes, sizes[i-1] + ds[i-1] / 2), decreasing = T)

  # interpolate density, other vars.
  new_state <- partition_spline(splines, sizes = new_sizes)

  return(new_state)
}
